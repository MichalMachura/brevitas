
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>brevitas.function package &#8212; Brevitas 0.6.1.dev24+g02fe33a.d20210910 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="brevitas.core package" href="brevitas.core.html" />
    <link rel="prev" title="API reference" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../index.html">
<p class="title">Brevitas</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../setup.html">
  Setup
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../user_guide/index.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  API reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../faq.html">
  FAQ
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../about.html">
  About
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   brevitas.function package
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="brevitas.core.html">
   brevitas.core package
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="brevitas.core.bit_width.html">
     brevitas.core.bit_width package
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="brevitas.core.function_wrapper.html">
     brevitas.core.function_wrapper package
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="brevitas.core.quant.html">
     brevitas.core.quant package
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="brevitas.core.scaling.html">
     brevitas.core.scaling package
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="brevitas.core.stats.html">
     brevitas.core.stats package
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#submodules">
   Submodules
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-brevitas.function.autograd_ste_ops">
   brevitas.function.autograd_ste_ops module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-brevitas.function.ops">
   brevitas.function.ops module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-brevitas.function.ops_ste">
   brevitas.function.ops_ste module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-brevitas.function.shape">
   brevitas.function.shape module
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-brevitas.function">
   Module contents
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="brevitas-function-package">
<h1>brevitas.function package<a class="headerlink" href="#brevitas-function-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-brevitas.function.autograd_ste_ops">
<span id="brevitas-function-autograd-ste-ops-module"></span><h2>brevitas.function.autograd_ste_ops module<a class="headerlink" href="#module-brevitas.function.autograd_ste_ops" title="Permalink to this headline">¶</a></h2>
<p>Implementation of various torch.autograd.Function with straight-through estimators.</p>
<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.AbsBinarySignGradFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">AbsBinarySignGradFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#AbsBinarySignGradFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.AbsBinarySignGradFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.abs.html#torch.abs" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.abs()</span></code></a> with a binary-sign backward, in order to
have subgradient 1 in 0. Compare with <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.abs.html#torch.abs" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.abs()</span></code></a>’ subgradient of 0 in 0.</p>
<p><code class="docutils literal notranslate"><span class="pre">AbsBinarySignGradFn.apply(*args)</span></code> is first aliased to <a class="reference internal" href="#brevitas.function.autograd_ste_ops.abs_binary_sign_grad_impl" title="brevitas.function.autograd_ste_ops.abs_binary_sign_grad_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">abs_binary_sign_grad(*args)</span></code></a> and then wrapped by
<a class="reference internal" href="#brevitas.function.ops_ste.abs_binary_sign_grad" title="brevitas.function.ops_ste.abs_binary_sign_grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">abs_binary_sign_grad()</span></code></a> when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <a class="reference internal" href="#brevitas.function.ops_ste.abs_binary_sign_grad" title="brevitas.function.ops_ste.abs_binary_sign_grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">abs_binary_sign_grad()</span></code></a> for details on the interface and
examples.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.BinarySignSteFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">BinarySignSteFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#BinarySignSteFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.BinarySignSteFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <a class="reference internal" href="#brevitas.function.ops.binary_sign" title="brevitas.function.ops.binary_sign"><code class="xref py py-func docutils literal notranslate"><span class="pre">binary_sign()</span></code></a> with a
straight-through gradient estimator.</p>
<p><code class="docutils literal notranslate"><span class="pre">BinarySignSteFn.apply(*args)</span></code> is first aliased to
<a class="reference internal" href="#brevitas.function.autograd_ste_ops.binary_sign_ste_impl" title="brevitas.function.autograd_ste_ops.binary_sign_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">binary_sign_ste_impl(*args)</span></code></a>
and then wrapped by <a class="reference internal" href="#brevitas.function.ops_ste.binary_sign_ste" title="brevitas.function.ops_ste.binary_sign_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">binary_sign_ste()</span></code></a> when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <a class="reference internal" href="#brevitas.function.ops_ste.binary_sign_ste" title="brevitas.function.ops_ste.binary_sign_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">binary_sign_ste()</span></code></a> for details on the interface and
examples.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.CeilSteFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">CeilSteFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#CeilSteFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.CeilSteFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.ceil.html#torch.ceil" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.ceil()</span></code></a> with a straight-through gradient estimator.</p>
<p><code class="docutils literal notranslate"><span class="pre">CeilSteFn.apply(*args)</span></code> is first aliased to <a class="reference internal" href="#brevitas.function.autograd_ste_ops.ceil_ste_impl" title="brevitas.function.autograd_ste_ops.ceil_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">ceil_ste_impl(*args)</span></code></a> and then wrapped by
<a class="reference internal" href="#brevitas.function.ops_ste.ceil_ste" title="brevitas.function.ops_ste.ceil_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">ceil_ste()</span></code></a> when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <a class="reference internal" href="#brevitas.function.ops_ste.ceil_ste" title="brevitas.function.ops_ste.ceil_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">ceil_ste()</span></code></a> for details on the interface and
examples.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.DPURoundSteFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">DPURoundSteFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#DPURoundSteFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.DPURoundSteFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <a class="reference internal" href="#brevitas.function.ops.dpu_round" title="brevitas.function.ops.dpu_round"><code class="xref py py-func docutils literal notranslate"><span class="pre">dpu_round()</span></code></a> with a
straight-through gradient estimator.</p>
<p><code class="docutils literal notranslate"><span class="pre">DPURoundSteFn.apply(*args)</span></code> is first aliased to <a class="reference internal" href="#brevitas.function.autograd_ste_ops.dpu_round_ste_impl" title="brevitas.function.autograd_ste_ops.dpu_round_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">dpu_round_ste_impl(*args)</span></code></a> and then wrapped by
<a class="reference internal" href="#brevitas.function.ops_ste.dpu_round_ste" title="brevitas.function.ops_ste.dpu_round_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">dpu_round_ste()</span></code></a> when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <a class="reference internal" href="#brevitas.function.ops_ste.dpu_round_ste" title="brevitas.function.ops_ste.dpu_round_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">dpu_round_ste()</span></code></a> for details on the interface and
examples.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.FloorSteFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">FloorSteFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#FloorSteFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.FloorSteFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.floor.html#torch.floor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.floor()</span></code></a> with a straight-through gradient estimator.</p>
<p><code class="docutils literal notranslate"><span class="pre">FloorSteFn.apply(*args)</span></code> is first aliased to <a class="reference internal" href="#brevitas.function.autograd_ste_ops.floor_ste_impl" title="brevitas.function.autograd_ste_ops.floor_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">floor_ste_impl(*args)</span></code></a> and then wrapped by
<a class="reference internal" href="#brevitas.function.ops_ste.floor_ste" title="brevitas.function.ops_ste.floor_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">floor_ste()</span></code></a> when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <a class="reference internal" href="#brevitas.function.ops_ste.floor_ste" title="brevitas.function.ops_ste.floor_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">floor_ste()</span></code></a> for details on the interface and
examples.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.InplaceTensorClampSteFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">InplaceTensorClampSteFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#InplaceTensorClampSteFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.InplaceTensorClampSteFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <a class="reference internal" href="#brevitas.function.ops.tensor_clamp_" title="brevitas.function.ops.tensor_clamp_"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp_()</span></code></a> with a
straight-through gradient estimator for the gradient of y w.r.t. to x, while the gradient of y
w.r.t. to min_val and max_val is always None.</p>
<p><code class="docutils literal notranslate"><span class="pre">InplaceTensorClampSteFn.apply(*args)</span></code> is first aliased to
<code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp_ste_impl_(*args)</span></code> and then wrapped by
<code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp_()</span></code> when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp_()</span></code> for details on the interface and
examples.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.RoundSteFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">RoundSteFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#RoundSteFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.RoundSteFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.round.html#torch.round" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.round()</span></code></a> with a straight-through gradient
estimator.</p>
<p><code class="docutils literal notranslate"><span class="pre">RoundSteFn.apply(*args)</span></code> is first aliased to <a class="reference internal" href="#brevitas.function.autograd_ste_ops.round_ste_impl" title="brevitas.function.autograd_ste_ops.round_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">round_ste_impl(*args)</span></code></a> and then wrapped by
<a class="reference internal" href="#brevitas.function.ops_ste.round_ste" title="brevitas.function.ops_ste.round_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">round_ste()</span></code></a> when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <a class="reference internal" href="#brevitas.function.ops_ste.round_ste" title="brevitas.function.ops_ste.round_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">round_ste()</span></code></a> for details on the interface and examples.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.RoundToZeroSteFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">RoundToZeroSteFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#RoundToZeroSteFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.RoundToZeroSteFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <a class="reference internal" href="#brevitas.function.ops.round_to_zero" title="brevitas.function.ops.round_to_zero"><code class="xref py py-func docutils literal notranslate"><span class="pre">round_to_zero()</span></code></a> with a
straight-through gradient estimator.</p>
<p><code class="docutils literal notranslate"><span class="pre">RoundToZeroSteFn.apply(*args)</span></code> is first aliased to <a class="reference internal" href="#brevitas.function.autograd_ste_ops.round_to_zero_ste_impl" title="brevitas.function.autograd_ste_ops.round_to_zero_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">round_to_zero_ste_impl(*args)</span></code></a> and then wrapped by
<a class="reference internal" href="#brevitas.function.ops_ste.round_to_zero_ste" title="brevitas.function.ops_ste.round_to_zero_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">round_to_zero_ste()</span></code></a> when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <a class="reference internal" href="#brevitas.function.ops_ste.round_to_zero_ste" title="brevitas.function.ops_ste.round_to_zero_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">round_to_zero_ste()</span></code></a> for details on the interface and
examples.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.ScalarClampMinSteFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">ScalarClampMinSteFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#ScalarClampMinSteFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.ScalarClampMinSteFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <code class="docutils literal notranslate"><span class="pre">torch.clamp_min</span></code> with a straight-through gradient estimator
for the gradient of y w.r.t. to x, while the gradient of y w.r.t. to <code class="docutils literal notranslate"><span class="pre">min_val</span></code> is always
<code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">ScalarClampMinSteFn.apply(*args)</span></code> is first aliased to <a class="reference internal" href="#brevitas.function.autograd_ste_ops.scalar_clamp_min_ste_impl" title="brevitas.function.autograd_ste_ops.scalar_clamp_min_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">scalar_clamp_min_ste_impl(*args)</span></code></a> and then wrapped by
<a class="reference internal" href="#brevitas.function.ops_ste.scalar_clamp_min_ste" title="brevitas.function.ops_ste.scalar_clamp_min_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">scalar_clamp_min_ste()</span></code></a> and invoked when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <a class="reference internal" href="#brevitas.function.ops_ste.scalar_clamp_ste" title="brevitas.function.ops_ste.scalar_clamp_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">scalar_clamp_ste()</span></code></a> for details on the interface and
examples.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.ScalarClampSteFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">ScalarClampSteFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#ScalarClampSteFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.ScalarClampSteFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <code class="docutils literal notranslate"><span class="pre">torch.clamp</span></code> with a straight-through gradient estimator
for the gradient of y w.r.t. to x, while the gradient of y w.r.t. to <code class="docutils literal notranslate"><span class="pre">min_val</span></code> and <code class="docutils literal notranslate"><span class="pre">min_val</span></code>
are always <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">ScalarClampSteFn.apply(*args)</span></code> is first aliased to <a class="reference internal" href="#brevitas.function.autograd_ste_ops.scalar_clamp_ste_impl" title="brevitas.function.autograd_ste_ops.scalar_clamp_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">scalar_clamp_ste_impl(*args)</span></code></a> and then wrapped by
<a class="reference internal" href="#brevitas.function.ops_ste.scalar_clamp_ste" title="brevitas.function.ops_ste.scalar_clamp_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">scalar_clamp_ste()</span></code></a> and invoked when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <a class="reference internal" href="#brevitas.function.ops_ste.scalar_clamp_ste" title="brevitas.function.ops_ste.scalar_clamp_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">scalar_clamp_ste()</span></code></a> for details on the interface and
examples.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.TensorClampSteFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">TensorClampSteFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#TensorClampSteFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.TensorClampSteFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <a class="reference internal" href="#brevitas.function.ops.tensor_clamp" title="brevitas.function.ops.tensor_clamp"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp()</span></code></a> with a
straight-through gradient estimator for the gradient of y w.r.t. to x, while the gradient of y
w.r.t. to min_val and max_val is always None.</p>
<p><code class="docutils literal notranslate"><span class="pre">TensorClampSteFn.apply(*args)</span></code> is first aliased to <a class="reference internal" href="#brevitas.function.autograd_ste_ops.tensor_clamp_ste_impl" title="brevitas.function.autograd_ste_ops.tensor_clamp_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp_ste_impl(*args)</span></code></a> and then wrapped by
<code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp()</span></code> when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp()</span></code> for details on the interface and
examples.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.TernarySignSteFn">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">TernarySignSteFn</span></span><a class="reference internal" href="../_modules/brevitas/function/autograd_ste_ops.html#TernarySignSteFn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.autograd_ste_ops.TernarySignSteFn" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Autograd function that implements <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.sign.html#torch.sign" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sign()</span></code></a> with a straight-through gradient estimator.</p>
<p><code class="docutils literal notranslate"><span class="pre">TernarySignSteFn.apply(*args)</span></code> is first aliased to <a class="reference internal" href="#brevitas.function.autograd_ste_ops.ternary_sign_ste_impl" title="brevitas.function.autograd_ste_ops.ternary_sign_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">ternary_sign_ste_impl(*args)</span></code></a> and then wrapped by
<a class="reference internal" href="#brevitas.function.ops_ste.ternary_sign_ste" title="brevitas.function.ops_ste.ternary_sign_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">ternary_sign_ste()</span></code></a> when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>.
See <a class="reference internal" href="#brevitas.function.ops_ste.ternary_sign_ste" title="brevitas.function.ops_ste.ternary_sign_ste"><code class="xref py py-func docutils literal notranslate"><span class="pre">ternary_sign_ste()</span></code></a> for details on the interface and
examples.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.abs_binary_sign_grad_impl">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">abs_binary_sign_grad_impl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ste_ops.abs_binary_sign_grad_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#brevitas.function.autograd_ste_ops.AbsBinarySignGradFn" title="brevitas.function.autograd_ste_ops.AbsBinarySignGradFn"><code class="xref py py-class docutils literal notranslate"><span class="pre">AbsBinarySignGradFn.apply(*args)</span></code></a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.binary_sign_ste_impl">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">binary_sign_ste_impl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ste_ops.binary_sign_ste_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#brevitas.function.autograd_ste_ops.BinarySignSteFn" title="brevitas.function.autograd_ste_ops.BinarySignSteFn"><code class="xref py py-class docutils literal notranslate"><span class="pre">BinarySignSteFn.apply(*args)</span></code></a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.ceil_ste_impl">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">ceil_ste_impl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ste_ops.ceil_ste_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#brevitas.function.autograd_ste_ops.CeilSteFn" title="brevitas.function.autograd_ste_ops.CeilSteFn"><code class="xref py py-class docutils literal notranslate"><span class="pre">CeilSteFn.apply(*args)</span></code></a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.dpu_round_ste_impl">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">dpu_round_ste_impl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ste_ops.dpu_round_ste_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#brevitas.function.autograd_ste_ops.DPURoundSteFn" title="brevitas.function.autograd_ste_ops.DPURoundSteFn"><code class="xref py py-class docutils literal notranslate"><span class="pre">DPURoundSteFn.apply(*args)</span></code></a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.floor_ste_impl">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">floor_ste_impl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ste_ops.floor_ste_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#brevitas.function.autograd_ste_ops.FloorSteFn" title="brevitas.function.autograd_ste_ops.FloorSteFn"><code class="xref py py-class docutils literal notranslate"><span class="pre">FloorSteFn.apply(*args)</span></code></a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.round_ste_impl">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">round_ste_impl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ste_ops.round_ste_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#brevitas.function.autograd_ste_ops.RoundSteFn" title="brevitas.function.autograd_ste_ops.RoundSteFn"><code class="xref py py-class docutils literal notranslate"><span class="pre">RoundSteFn.apply(*args)</span></code></a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.round_to_zero_ste_impl">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">round_to_zero_ste_impl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ste_ops.round_to_zero_ste_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#brevitas.function.autograd_ste_ops.RoundToZeroSteFn" title="brevitas.function.autograd_ste_ops.RoundToZeroSteFn"><code class="xref py py-class docutils literal notranslate"><span class="pre">RoundToZeroSteFn.apply(*args)</span></code></a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.scalar_clamp_min_ste_impl">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">scalar_clamp_min_ste_impl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ste_ops.scalar_clamp_min_ste_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#brevitas.function.autograd_ste_ops.ScalarClampMinSteFn" title="brevitas.function.autograd_ste_ops.ScalarClampMinSteFn"><code class="xref py py-class docutils literal notranslate"><span class="pre">ScalarClampMinSteFn.apply(*args)</span></code></a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.scalar_clamp_ste_impl">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">scalar_clamp_ste_impl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ste_ops.scalar_clamp_ste_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#brevitas.function.autograd_ste_ops.ScalarClampSteFn" title="brevitas.function.autograd_ste_ops.ScalarClampSteFn"><code class="xref py py-class docutils literal notranslate"><span class="pre">ScalarClampSteFn.apply(*args)</span></code></a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.tensor_clamp_ste_impl">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">tensor_clamp_ste_impl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ste_ops.tensor_clamp_ste_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#brevitas.function.autograd_ste_ops.TensorClampSteFn" title="brevitas.function.autograd_ste_ops.TensorClampSteFn"><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorClampSteFn.apply(*args)</span></code></a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.autograd_ste_ops.ternary_sign_ste_impl">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.autograd_ste_ops.</span></span><span class="sig-name descname"><span class="pre">ternary_sign_ste_impl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#brevitas.function.autograd_ste_ops.ternary_sign_ste_impl" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for <a class="reference internal" href="#brevitas.function.autograd_ste_ops.TernarySignSteFn" title="brevitas.function.autograd_ste_ops.TernarySignSteFn"><code class="xref py py-class docutils literal notranslate"><span class="pre">TernarySignSteFn.apply(*args)</span></code></a></p>
</dd></dl>

</div>
<div class="section" id="module-brevitas.function.ops">
<span id="brevitas-function-ops-module"></span><h2>brevitas.function.ops module<a class="headerlink" href="#module-brevitas.function.ops" title="Permalink to this headline">¶</a></h2>
<p>Implementation of various core operations often performed as part of quantization.
The implemented functions adheres to the restriction imposed by Pytorch 1.1.0’s TorchScript compiler.</p>
<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops.binary_sign">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops.</span></span><span class="sig-name descname"><span class="pre">binary_sign</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops.html#binary_sign"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops.binary_sign" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the 2-valued sign of an input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the 2-valued sign tensor of the input tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">binary_sign</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]))</span>
<span class="go">tensor([ 1., -1.,  1.])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops.dpu_round">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops.</span></span><span class="sig-name descname"><span class="pre">dpu_round</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops.html#dpu_round"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops.dpu_round" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute DPU rounding.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>rounded input tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dpu_round</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]))</span>
<span class="go">tensor([-1., -0.,  0.,  2.])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops.identity">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops.</span></span><span class="sig-name descname"><span class="pre">identity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops.html#identity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops.identity" title="Permalink to this definition">¶</a></dt>
<dd><p>Identity function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input Tensor</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>THe input tensor x</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">identity</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.7</span><span class="p">))</span>
<span class="go">tensor(1.7)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops.max_int">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops.</span></span><span class="sig-name descname"><span class="pre">max_int</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">narrow_range</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bit_width</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops.html#max_int"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops.max_int" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the maximum integer representable by a given number of bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Indicates whether the represented integer is signed or not.</p></li>
<li><p><strong>narrow_range</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Indicates whether to narrow the maximum unsigned value represented by 1.</p></li>
<li><p><strong>bit_width</strong> (<em>Tensor</em>) – Number of bits available for the representation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Maximum integer that can be represented according to the input arguments.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">max_int</span><span class="p">(</span><span class="n">signed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bit_width</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<span class="go">tensor(127)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">max_int</span><span class="p">(</span><span class="n">signed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bit_width</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<span class="go">tensor(254)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">max_int</span><span class="p">(</span><span class="n">signed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bit_width</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<span class="go">tensor(127)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">max_int</span><span class="p">(</span><span class="n">signed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bit_width</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<span class="go">tensor(255)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops.min_int">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops.</span></span><span class="sig-name descname"><span class="pre">min_int</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">signed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">narrow_range</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bit_width</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops.html#min_int"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops.min_int" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the minimum integer representable by a given number of bits.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>signed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Indicates whether the represented integer is signed or not.</p></li>
<li><p><strong>narrow_range</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Indicates whether to narrow the minimum value represented by 1.</p></li>
<li><p><strong>bit_width</strong> (<em>Tensor</em>) – Number of bits available for the representation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Maximum unsigned integer that can be represented according to the input arguments.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">min_int</span><span class="p">(</span><span class="n">signed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bit_width</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<span class="go">tensor(-127)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">min_int</span><span class="p">(</span><span class="n">signed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bit_width</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<span class="go">tensor(0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">min_int</span><span class="p">(</span><span class="n">signed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bit_width</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<span class="go">tensor(-128)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">min_int</span><span class="p">(</span><span class="n">signed</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">narrow_range</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bit_width</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<span class="go">tensor(0)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops.round_to_zero">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops.</span></span><span class="sig-name descname"><span class="pre">round_to_zero</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops.html#round_to_zero"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops.round_to_zero" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute rounding towards zero.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – input tensor.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>rounded input tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">round_to_zero</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]))</span>
<span class="go">tensor([-1., -0.,  0.,  1.])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops.tensor_clamp">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops.</span></span><span class="sig-name descname"><span class="pre">tensor_clamp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_val</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops.html#tensor_clamp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops.tensor_clamp" title="Permalink to this definition">¶</a></dt>
<dd><p>Generalized clamp function with support for tensors as clamping values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>) – Input on which to apply the clamp operation</p></li>
<li><p><strong>min_val</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>) – Minimum values for the clamp operation.</p></li>
<li><p><strong>max_val</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>) – Maximum values for the clamp operation.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>x, min_val, max_val need to be broadcastable.</p>
<p class="rubric">Notes</p>
<p>Differentiable w.r.t. x, min_val, max_val.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Input <cite>x</cite> clamped between the provided minimum and maximum tensors.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tensor_clamp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.7</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="go">tensor([1.0000, 0.0000, 0.1000])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops.tensor_clamp_">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops.</span></span><span class="sig-name descname"><span class="pre">tensor_clamp_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_val</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops.html#tensor_clamp_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops.tensor_clamp_" title="Permalink to this definition">¶</a></dt>
<dd><p>In-place variant of <a class="reference internal" href="#brevitas.function.ops.tensor_clamp" title="brevitas.function.ops.tensor_clamp"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp()</span></code></a>.
Not differentiable wrt to any of the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-brevitas.function.ops_ste">
<span id="brevitas-function-ops-ste-module"></span><h2>brevitas.function.ops_ste module<a class="headerlink" href="#module-brevitas.function.ops_ste" title="Permalink to this headline">¶</a></h2>
<p>Implementation of various functions with a straight-through gradient estimators, dispatched to
either a native just-in-time compiled backend (when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>) or to an autograd
Function implemented in <a class="reference internal" href="#module-brevitas.function.autograd_ste_ops" title="brevitas.function.autograd_ste_ops"><code class="xref py py-obj docutils literal notranslate"><span class="pre">autograd_ste_ops</span></code></a> (when env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>).</p>
<p>The native backend is enabled when <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT</span></code> is enabled to allow for end-to-end compilation
of the built-in quantizers, since as of Pytorch 1.8.1 a torch.autograd.Function is not supported by
the compiler.</p>
<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.abs_binary_sign_grad">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">abs_binary_sign_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#abs_binary_sign_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.abs_binary_sign_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.abs.html#torch.abs" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.abs()</span></code></a> with a binary-sign backward, in order to
have subgradient 1 in 0. Compare with <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.abs.html#torch.abs" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.abs()</span></code></a>’ subgradient of 0 in 0.</p>
<p class="rubric">Notes</p>
<p>Wrapper for either <a class="reference internal" href="#brevitas.function.autograd_ste_ops.abs_binary_sign_grad_impl" title="brevitas.function.autograd_ste_ops.abs_binary_sign_grad_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">abs_binary_sign_grad_impl()</span></code></a>
(with env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its native just-in-time compiled variant (with
<code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">abs_binary_sign_grad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([0.], grad_fn=&lt;AbsBinarySignGradFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.binary_sign_ste">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">binary_sign_ste</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#binary_sign_ste"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.binary_sign_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <a class="reference internal" href="#brevitas.function.ops.binary_sign" title="brevitas.function.ops.binary_sign"><code class="xref py py-func docutils literal notranslate"><span class="pre">binary_sign()</span></code></a> with a straight-through
gradient estimator.</p>
<p class="rubric">Notes</p>
<p>Wrapper for either <a class="reference internal" href="#brevitas.function.autograd_ste_ops.binary_sign_ste_impl" title="brevitas.function.autograd_ste_ops.binary_sign_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">binary_sign_ste_impl()</span></code></a> (with
env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its native just-in-time compiled variant (with
<code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.7</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">binary_sign_ste</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([ 1.,  1., -1.], grad_fn=&lt;BinarySignSteFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.ceil_ste">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">ceil_ste</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#ceil_ste"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.ceil_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.ceil.html#torch.ceil" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.ceil()</span></code></a> with a straight-through gradient estimator.</p>
<p class="rubric">Notes</p>
<p>Wrapper for either <a class="reference internal" href="#brevitas.function.autograd_ste_ops.ceil_ste_impl" title="brevitas.function.autograd_ste_ops.ceil_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">ceil_ste_impl()</span></code></a> (with env
<code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its native just-in-time compiled variant (with <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.7</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">ceil_ste</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([ 2., -1.], grad_fn=&lt;CeilSteFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.dpu_round_ste">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">dpu_round_ste</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#dpu_round_ste"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.dpu_round_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <a class="reference internal" href="#brevitas.function.ops.dpu_round" title="brevitas.function.ops.dpu_round"><code class="xref py py-func docutils literal notranslate"><span class="pre">dpu_round()</span></code></a> with a straight-through
gradient estimator.</p>
<p class="rubric">Notes</p>
<p>Wrapper for either <a class="reference internal" href="#brevitas.function.autograd_ste_ops.dpu_round_ste_impl" title="brevitas.function.autograd_ste_ops.dpu_round_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">dpu_round_ste_impl()</span></code></a> (with
env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its native just-in-time compiled variant (with
<code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.7</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">dpu_round_ste</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([ 2., -2.], grad_fn=&lt;DPURoundSteFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.floor_ste">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">floor_ste</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#floor_ste"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.floor_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.floor.html#torch.floor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.floor()</span></code></a> with a straight-through gradient estimator.</p>
<p class="rubric">Notes</p>
<p>Wrapper for either <a class="reference internal" href="#brevitas.function.autograd_ste_ops.floor_ste_impl" title="brevitas.function.autograd_ste_ops.floor_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">floor_ste_impl()</span></code></a> (with env
<code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its native just-in-time compiled variant (with <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.7</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">floor_ste</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([ 1., -2.], grad_fn=&lt;FloorSteFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.round_ste">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">round_ste</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#round_ste"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.round_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.round.html#torch.round" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.round()</span></code></a> with a straight-through gradient estimator.</p>
<p class="rubric">Notes</p>
<p>Wrapper for either <a class="reference internal" href="#brevitas.function.autograd_ste_ops.round_ste_impl" title="brevitas.function.autograd_ste_ops.round_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">round_ste_impl()</span></code></a> (with env
<code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its native just-in-time compiled variant (with <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.7</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">round_ste</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([ 2., -2.], grad_fn=&lt;RoundSteFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.round_to_zero_ste">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">round_to_zero_ste</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#round_to_zero_ste"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.round_to_zero_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <a class="reference internal" href="#brevitas.function.ops.round_to_zero" title="brevitas.function.ops.round_to_zero"><code class="xref py py-func docutils literal notranslate"><span class="pre">round_to_zero()</span></code></a> with a straight-through
gradient estimator.</p>
<p class="rubric">Notes</p>
<p>Wrapper for either <a class="reference internal" href="#brevitas.function.autograd_ste_ops.round_to_zero_ste_impl" title="brevitas.function.autograd_ste_ops.round_to_zero_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">round_to_zero_ste_impl()</span></code></a> (with
env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its native just-in-time compiled variant (with
<code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.7</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">round_to_zero_ste</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([ 1., -1.], grad_fn=&lt;RoundToZeroSteFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.scalar_clamp_min_ste">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">scalar_clamp_min_ste</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_val</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#scalar_clamp_min_ste"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.scalar_clamp_min_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.clamp_min()</span></code> with a straight-through gradient estimator
for the gradient of output y w.r.t. to <code class="docutils literal notranslate"><span class="pre">x</span></code>, while the gradient of y w.r.t. to <code class="docutils literal notranslate"><span class="pre">min_val</span></code> is
always <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>) – input tensor to clamp.</p></li>
<li><p><strong>min_val</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>) – scalar value to use as lower bound for the input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>clamped output tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Wrapper for either <a class="reference internal" href="#brevitas.function.autograd_ste_ops.scalar_clamp_min_ste_impl" title="brevitas.function.autograd_ste_ops.scalar_clamp_min_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">scalar_clamp_min_ste_impl()</span></code></a>
(with env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its C++ just-in-time compiled variant
(with <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">scalar_clamp_min_ste</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([ 1.5000,  0.4000, -1.0000], grad_fn=&lt;ScalarClampMinSteFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.scalar_clamp_ste">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">scalar_clamp_ste</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_val</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#scalar_clamp_ste"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.scalar_clamp_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.clamp.html#torch.clamp" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.clamp()</span></code></a> with a straight-through gradient estimator
for the gradient of the output w.r.t. to <code class="docutils literal notranslate"><span class="pre">x</span></code>, while the gradient of <code class="docutils literal notranslate"><span class="pre">y</span></code> w.r.t. to <code class="docutils literal notranslate"><span class="pre">min_val</span></code>
and <code class="docutils literal notranslate"><span class="pre">max_val</span></code> is always <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>) – input tensor to clamp.</p></li>
<li><p><strong>min_val</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>) – scalar value to use as lower bound for the input tensor.</p></li>
<li><p><strong>max_val</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code></a>) – scalar value to use as upper bound for the input tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>clamped output tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Wrapper for either <a class="reference internal" href="#brevitas.function.autograd_ste_ops.scalar_clamp_ste_impl" title="brevitas.function.autograd_ste_ops.scalar_clamp_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">scalar_clamp_ste_impl()</span></code></a>
(with env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its C++ just-in-time compiled variant
(with <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">scalar_clamp_ste</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([ 1.0000,  0.4000, -1.0000], grad_fn=&lt;ScalarClampSteFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.tensor_clamp_ste">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">tensor_clamp_ste</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_val</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#tensor_clamp_ste"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.tensor_clamp_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <a class="reference internal" href="#brevitas.function.ops.tensor_clamp" title="brevitas.function.ops.tensor_clamp"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp()</span></code></a> with a straight-through
gradient estimator for the gradient of y w.r.t. to x, while the gradient of y w.r.t. to min_val
and max_val is always None.</p>
<p class="rubric">Notes</p>
<p>Wrapper for either <a class="reference internal" href="#brevitas.function.autograd_ste_ops.tensor_clamp_ste_impl" title="brevitas.function.autograd_ste_ops.tensor_clamp_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp_ste_impl()</span></code></a> (with
env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its native just-in-time compiled variant (with
<code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">tensor_clamp_ste</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([ 1.0000,  0.4000, -0.5000], grad_fn=&lt;TensorClampSteFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.tensor_clamp_ste_">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">tensor_clamp_ste_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_val</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#tensor_clamp_ste_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.tensor_clamp_ste_" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <a class="reference internal" href="#brevitas.function.ops.tensor_clamp_" title="brevitas.function.ops.tensor_clamp_"><code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp_()</span></code></a> with a straight-through
gradient estimator for the gradient of y w.r.t. to x, while the gradient of y w.r.t. to min_val
and max_val is always None.</p>
<p class="rubric">Notes</p>
<p>Wrapper for either <code class="xref py py-func docutils literal notranslate"><span class="pre">tensor_clamp_ste_impl_()</span></code> (with
env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its C++ just-in-time compiled variant (with <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">tensor_clamp_ste_</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([ 1.0000,  0.4000, -0.5000], grad_fn=&lt;InplaceTensorClampSteFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.ops_ste.ternary_sign_ste">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.ops_ste.</span></span><span class="sig-name descname"><span class="pre">ternary_sign_ste</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/ops_ste.html#ternary_sign_ste"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.ops_ste.ternary_sign_ste" title="Permalink to this definition">¶</a></dt>
<dd><p>Function that implements <a class="reference external" href="https://pytorch.org/docs/master/generated/torch.sign.html#torch.sign" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sign()</span></code></a> with a straight-through gradient estimator.</p>
<p class="rubric">Notes</p>
<p>Wrapper for either <a class="reference internal" href="#brevitas.function.autograd_ste_ops.ternary_sign_ste_impl" title="brevitas.function.autograd_ste_ops.ternary_sign_ste_impl"><code class="xref py py-func docutils literal notranslate"><span class="pre">ternary_sign_ste_impl()</span></code></a> (with
env <code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=0</span></code>) or its native just-in-time compiled variant (with
<code class="docutils literal notranslate"><span class="pre">BREVITAS_JIT=1</span></code>).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.7</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">ternary_sign_ste</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>
<span class="go">tensor([ 1.,  0., -1.], grad_fn=&lt;TernarySignSteFnBackward&gt;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span> <span class="o">==</span> <span class="n">grad</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+git5286f99 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-brevitas.function.shape">
<span id="brevitas-function-shape-module"></span><h2>brevitas.function.shape module<a class="headerlink" href="#module-brevitas.function.shape" title="Permalink to this headline">¶</a></h2>
<p>Implementation of various functions to compute shapes that induce flattening along certain
dimensions of a tensor.</p>
<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.shape.over_batch_over_output_channels">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.shape.</span></span><span class="sig-name descname"><span class="pre">over_batch_over_output_channels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/shape.html#over_batch_over_output_channels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.shape.over_batch_over_output_channels" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a shape s such that x.view(s) is a 3-dim tensor with batches
at dimension 0, output channels at dimension 1, and any other feature at dimension 2.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor with batches at dimension 0 and output channels at dimension 1.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple containing the 3-dim shape.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">over_batch_over_output_channels</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="go">(2, 3, -1)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.shape.over_batch_over_tensor">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.shape.</span></span><span class="sig-name descname"><span class="pre">over_batch_over_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/shape.html#over_batch_over_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.shape.over_batch_over_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the shape s such that x.view(s) is a 2-dim tensor with batches
at dimension 0 and any other feature at dimension 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor with batches at dimension 0.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tuple containing the 2-dim shape.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">over_batch_over_tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="go">(2, -1)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.shape.over_output_channels">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.shape.</span></span><span class="sig-name descname"><span class="pre">over_output_channels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/shape.html#over_output_channels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.shape.over_output_channels" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the shape s such that x.view(s) is a 2-dim tensor with output channels
at dimension 0 and any other feature at dimension 1.</p>
<p>Args:
x (Tensor): Input tensor with output channels at dimension 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>]</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple containing the 2-dim shape.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">over_output_channels</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="go">(2, -1)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="brevitas.function.shape.over_tensor">
<span class="sig-prename descclassname"><span class="pre">brevitas.function.shape.</span></span><span class="sig-name descname"><span class="pre">over_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/brevitas/function/shape.html#over_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#brevitas.function.shape.over_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the shape s such that x.view(s) is a flat tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – Input tensor.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The number -1 corresponding to a flat shape.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">over_tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="go">-1</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="module-brevitas.function">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-brevitas.function" title="Permalink to this headline">¶</a></h2>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">API reference</a>
    <a class='right-next' id="next-link" href="brevitas.core.html" title="next page">brevitas.core package</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021 - Xilinx, Inc.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.1.2.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>